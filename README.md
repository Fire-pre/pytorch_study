# pytorch_study


# 2025 12 12
今天学习了Pytorch的基本语法，明白了非线性激活函数的用途

#2025 12 20
今天学习了SimVP的模型部分：知道了模型部分的基本流程：
数据全部处理好之后将其送入模型，在该模型中首先我们通过Encoder部分将真实世界的维度抽象为矩阵形式，不改变分辨率只改变内容，与之对应的Decoder部分一定要在结构上和Encoder部分对称。这两部分负责空间特征的提取
经过编码器处理之后我们将其送到我们的translator部分，这一部分由多个Inception组成，提取时间特征。首先我们还是要通过一个encoder，这个encoder是改变内容的，经过多层卷积提取最深层次的特征，
最后定义SimVP类，用来调用上述方法。

#2025 12 21
学习训练的流程首先我们需要准备数据集dataset，然后通过dataloader处理dataset，实例化模型，处理好之后调用模型，梯度清零、计算loss、计算梯度、反向传播多次循环记录最小损失的参数

#2025 12 23
今天学习了exp.py文件，也就是训练的过程。整个代码流程如下：

首先通过Exp初始化，其中的方法均为其私有

然后在preparation方法中，进行准备，创建一个文件夹用以存储我们的数据，且在里面创建checkpoints文件，避免文件凌乱。将我们需要的数据全部存进去，然后我们需要清空之前的记录，并且规定现在我们应该存入什么样的数据。然后传入数据，调用模型。

通过build_model方法调用模型，此时我们一定要把形状的参数转化成元组，避免在运算过程中被改变

通过get_data方法传入数据，我们将数据变成字典形传入，若没有验证集我们就用测试集

在select_optimizer方法中我们选择Adam优化器，并且通过OneCycleLR来调整lr。返回优化结果

在select_criterion方法中选择MSE来评估我们的模型误差

在train方法中，我们通过规定的迭代次数epochs进行训练，并将训练的损失存入一个列表，训练结束后，将梯度清零，进行预测，将预测值与真实值做损失并存储到列表。然后进行反向传播，优化，调整学习率，然后计算损失的平均值存入train_loss中。
提前设定一个次数args.log_step，当epoch是他的整数倍的时候进行验证，此时不需要梯度，没训练设定次数的一百倍的时候就保存一次参数，用recoeder函数记录下loss最小的模型参数。并且返回这个模型参数

vali方法，进行验证，将预测值、真实值以及总损失记录到列表，
设定迭代1000次，在这个循环中，调用模型，计算预测值pred_y，然后计算损失存储，所有计算完毕之后算平均loss，将预测值和真实值的列表拼接成一个大的矩阵，进行整体的比较。全部完成之后将模型切换到训练模式，返回损失。

test方法：将输入，真实值以及预测值都存到列表中，先将所有数据转化为Numpy形，然后将其拼接为大矩阵，然后将其存储，若存储文件不存在就创建一个，最后返回mse误差

所以实验配置都存储在args里，而训练、验证、测试都存储在Exp里面。
读取数据：在get_data中，进行读取。同时拿到data_mean,data_std，用于后续计算指标时的“反归一化”。
实例化：在guid_model里实例化，但是在preparation中被调用
模型加载：在train函数中进行模型加载
前向传播，在训练部分，计算预测值。
通过MSE计算损失
所以整个训练流程为：初始化-get_data-build_model-train（-vali-recoder）-使用loss最低的模型，-test-归档损失。


#2025-12-28
今天开始看PastNet_Introducing_Physi，了解了一些相关背景。之前的方法，使用深度神经网络来捕捉空间信息然后联合视频预测，现有的深度神经网络例如CNN和Vision Transformer都对算力需求高。此外归纳偏执是加在模型里面，所以这样会造成内在物理信息的缺失而且需要较高的算力不适用在高频视频预测。所以我们提出了新的方法，通过数据引入物理归纳偏置，在光谱空间引入卷积算子，然后使用傅立叶逆变换产生输出。主要是引入离散的时空模型，在产生复杂的时空信号过程中，不仅仅估计内在维度而且引入记忆库来离散化局部特征，用记忆库中最近的查询来替代局部特征。最终采用一个反卷积的解码器输出预测，这些结果都与谱空间的输出相结合。并且通过傅立叶域中整合可学习的神经网络，引入了视频帧潜在的偏微分方程的归纳偏置


#2025-12-25
数据压缩是提升训练和推理过程的重要方法。一、是通过hash的方法，在估计最近的临界研究是很有效的。二、是神经量化。当前的多密码本量化类似于k-means聚类，在代码本中存储中心和分配。我们的模型通过离散局部特征来提升高频视频预测的效率。

PastNet的概览，它包含基于傅立叶的物理引导（FPG）、离散的时空模型（DST），可编程功能接口（PFI）模型首先离散视频帧到一个非折叠的patches然后引入有物理偏置的基于傅立叶的光谱滤波器。然后它也通过卷积神经网络捕捉空间信号。DST模型是一个引入了记忆库来离散局部特征的编码-解码结构

由于现存解法通常忽视了隐藏的物理信息和使用更大的计算空间，为了解决这些问题我们的方法，引入了基于傅立叶的物理引导模型和离散的时空模型来提升视频预测的效率。FPG模型首先将帧展平然后引入物理归纳偏置。然后DST模型不仅仅估计内在的维度也引入了离散的记忆库来提升捕捉时空信息的效率。

在时间域假设视频轨迹代表动态的物理系统。这个系统由时间步组成，在空间域，捕捉测量C颜色空间随时间变化，表示为一个H*W的网格。我们希望使用时空数据来推导物理先验和在空间和时间维度上融合特征表示学习和预测最可能的未来序列
